{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "sys.path.append('../ctpn.pytorch/')\n",
    "sys.path.append('../crnn.pytorch/')\n",
    "from ctpn import config\n",
    "from ctpn.ctpn import CTPN_Model\n",
    "from ctpn.utils import gen_anchor, transform_bbox, clip_bbox, filter_bbox, nms, TextProposalConnectorOriented\n",
    "import crnn\n",
    "from config import cfg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_boxes(image, display = True, prob_thresh = 0.5):\n",
    "    h, w = image.shape[:2]\n",
    "    rescale_fac = max(h, w) / 1000\n",
    "    if rescale_fac > 1.0:\n",
    "        h = int(h / rescale_fac)\n",
    "        w = int(w / rescale_fac)\n",
    "        image = cv2.resize(image, (w,h))\n",
    "        h, w = image.shape[:2]\n",
    "    image_c = image.copy()\n",
    "    image = image.astype(np.float32) - config.IMAGE_MEAN\n",
    "    image = torch.from_numpy(image.transpose(2, 0, 1)).unsqueeze(0).float().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        cls, regr = model_ctpn(image)\n",
    "        cls_prob = F.softmax(cls, dim=-1).cpu().numpy()\n",
    "        regr = regr.cpu().numpy()\n",
    "        anchor = gen_anchor((int(h / 16), int(w / 16)), 16)\n",
    "        bbox = transform_bbox(anchor, regr)\n",
    "        bbox = clip_bbox(bbox, [h, w])\n",
    "\n",
    "        fg = np.where(cls_prob[0, :, 1] > prob_thresh)[0]\n",
    "        select_anchor = bbox[fg, :]\n",
    "        select_score = cls_prob[0, fg, 1]\n",
    "        select_anchor = select_anchor.astype(np.int32)\n",
    "        keep_index = filter_bbox(select_anchor, 16)\n",
    "\n",
    "        select_anchor = select_anchor[keep_index]\n",
    "        select_score = select_score[keep_index]\n",
    "        select_score = np.reshape(select_score, (select_score.shape[0], 1))\n",
    "        nmsbox = np.hstack((select_anchor, select_score))\n",
    "        keep = nms(nmsbox, 0.3)\n",
    "        select_anchor = select_anchor[keep]\n",
    "        select_score = select_score[keep]\n",
    "\n",
    "        textConn = TextProposalConnectorOriented()\n",
    "        text = textConn.get_text_lines(select_anchor, select_score, [h, w])\n",
    "        if display:\n",
    "            for i in text:\n",
    "                s = str(round(i[-1] * 100, 2)) + '%'\n",
    "                i = [int(j) for j in i]\n",
    "                cv2.line(image_c, (i[0], i[1]), (i[2], i[3]), (0, 0, 255), 2)\n",
    "                cv2.line(image_c, (i[0], i[1]), (i[4], i[5]), (0, 0, 255), 2)\n",
    "                cv2.line(image_c, (i[6], i[7]), (i[2], i[3]), (0, 0, 255), 2)\n",
    "                cv2.line(image_c, (i[4], i[5]), (i[6], i[7]), (0, 0, 255), 2)\n",
    "                #cv2.putText(image_c, s, (i[0]+13, i[1]+13), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "\n",
    "        return text, image_c, rescale_fac\n",
    "    \n",
    "def load_image(image):\n",
    "    h, w = image.shape[:2]\n",
    "    if h != 32 and h < w:\n",
    "        new_w = int(w * 32 / h)\n",
    "        image = cv2.resize(image, (new_w, 32))\n",
    "    if w != 32 and w < h:\n",
    "        new_h = int(h * 32 / w)\n",
    "        image = cv2.resize(image, (32, new_h))\n",
    "\n",
    "    image = Image.fromarray(image).convert('L')\n",
    "    # cv2.imwrite(image_path, np.array(image))\n",
    "    image = np.array(image)\n",
    "    if h < w:\n",
    "        image = np.array(image).T  # [W,H]\n",
    "    image = image.astype(np.float32) / 255.\n",
    "    image -= 0.5\n",
    "    image /= 0.5\n",
    "    image = image[np.newaxis, np.newaxis, :, :]  # [B,C,W,H]\n",
    "    return image\n",
    "\n",
    "def get_minAreaRect(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bitwise_not(gray)\n",
    "    thresh = cv2.threshold(gray, 0, 255,\n",
    "        cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    coords = np.column_stack(np.where(thresh > 0))\n",
    "    return cv2.minAreaRect(coords)\n",
    "\n",
    "def rotate_bound(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = h\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "    return cv2.warpAffine(image, M, (nW, nH),flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "def rotate_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bitwise_not(gray)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    coords = np.column_stack(np.where(thresh > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = img.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "weights_ctpn = '/notebook/aigo-ocr/ctpn.pytorch/weights/ctpn.pth'\n",
    "model_ctpn = CTPN_Model().to(device)\n",
    "model_ctpn.load_state_dict(torch.load(weights_ctpn, map_location=device)['model_state_dict'])\n",
    "model_ctpn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_crnn = '/notebook/aigo-ocr/crnn.pytorch/models/crnn.horizontal.061.pth'\n",
    "alpha = cfg.word.get_all_words()\n",
    "model_crnn = crnn.CRNN(num_classes=len(alpha))\n",
    "model_crnn.load_state_dict(torch.load(weights_crnn, map_location=device)['model'])\n",
    "model_crnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/notebook/images/insurance/IMG_5620.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "img_rotated = rotate_image(img)\n",
    "text, out_img, scale = get_text_boxes(img_rotated, prob_thresh=0.1)\n",
    "plt.figure(figsize=(20,40))\n",
    "plt.imshow(out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "padding = 10\n",
    "for k in range(text.shape[0]):\n",
    "    X = text[k][:8][::2]\n",
    "    Y = text[k][:8][1::2]\n",
    "    x1, y1 = int(min(X) * scale) - padding, int(min(Y) * scale) + 5\n",
    "    x2, y2 = int(max(X) * scale) + padding, int(max(Y) * scale) - 5\n",
    "    img_crop = img[y1:y2, x1:x2]\n",
    "    img_crnn = load_image(img_crop)\n",
    "    img_crnn = torch.FloatTensor(img_crnn)\n",
    "    predict = model_crnn(img_crnn)[0].detach().numpy()\n",
    "    label = np.argmax(predict[:], axis=1)\n",
    "    label = [alpha[class_id] for class_id in label]\n",
    "    label = [k for k, g in itertools.groupby(list(label))]\n",
    "    label = ''.join(label).replace(' ', '')\n",
    "    print(label)\n",
    "    plt.figure(figsize=(20,40))\n",
    "    plt.imshow(img_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
